{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from scipy.stats import gmean\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "\n",
    "model_dir = 'data/precomputed/xgb/'\n",
    "images_dir = 'data/train_full/'\n",
    "list_images = glob.glob('{}/*/*g'.format(images_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup tensorFlow graph initiation\n",
    "def create_graph():\n",
    "    with gfile.FastGFile(os.path.join(model_dir, 'inceptionv3.pb'), 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = pickle.load(open('data/precomputed/xgb/features', 'rb'))\n",
    "labels = pickle.load(open('data/precomputed/xgb/labels', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "labels = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_xgboost():\n",
    "    x = features\n",
    "    y = labels\n",
    "    \n",
    "    clfs = []\n",
    "    \n",
    "    num_round = 2000\n",
    "    param = {'max_depth': 6,\n",
    "             'n_estimators': 1500,\n",
    "             'min_child_weight': 100,\n",
    "             'learning_rate': 0.04,\n",
    "             'num_class': 8,\n",
    "             'objective': 'multi:softprob',\n",
    "             'eval_metric': 'mlogloss',\n",
    "             'nthread': 8,\n",
    "             'subsample': 0.9,\n",
    "             'colsample_bytree': 0.9,\n",
    "             'early_stopping_rounds': 20,\n",
    "             'silent': 1,\n",
    "             'seed': 42}\n",
    "    \n",
    "    kf = KFold(n_splits=5, random_state=2017, shuffle=True)\n",
    "    for train_index, test_index in kf.split(x, y):\n",
    "        trn_x, val_x = x[train_index,:], x[test_index,:]\n",
    "        trn_y, val_y = y[train_index], y[test_index]\n",
    "        \n",
    "        d_train = xgb.DMatrix(trn_x, label=trn_y)\n",
    "        d_val = xgb.DMatrix(val_x, label=val_y)\n",
    "        watchlist  = [(d_val,'eval'), (d_train,'train')]\n",
    "        \n",
    "        clf = xgb.train(param, d_train, num_round, watchlist, verbose_eval=499)\n",
    "        clfs.append(clf)\n",
    "\n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-mlogloss:2.03809\ttrain-mlogloss:2.03614\n",
      "[500]\teval-mlogloss:0.639979\ttrain-mlogloss:0.418838\n",
      "[1000]\teval-mlogloss:0.559717\ttrain-mlogloss:0.307672\n",
      "[1500]\teval-mlogloss:0.538929\ttrain-mlogloss:0.277124\n",
      "[0]\teval-mlogloss:2.04008\ttrain-mlogloss:2.03727\n",
      "[500]\teval-mlogloss:0.689815\ttrain-mlogloss:0.424566\n",
      "[1000]\teval-mlogloss:0.600729\ttrain-mlogloss:0.311414\n",
      "[1500]\teval-mlogloss:0.578866\ttrain-mlogloss:0.280422\n",
      "[0]\teval-mlogloss:2.04025\ttrain-mlogloss:2.03618\n",
      "[500]\teval-mlogloss:0.688279\ttrain-mlogloss:0.419741\n",
      "[1000]\teval-mlogloss:0.604386\ttrain-mlogloss:0.311304\n",
      "[1500]\teval-mlogloss:0.580504\ttrain-mlogloss:0.280706\n",
      "[0]\teval-mlogloss:2.03887\ttrain-mlogloss:2.03678\n",
      "[500]\teval-mlogloss:0.669617\ttrain-mlogloss:0.418214\n",
      "[1000]\teval-mlogloss:0.589371\ttrain-mlogloss:0.308541\n",
      "[1500]\teval-mlogloss:0.568377\ttrain-mlogloss:0.278243\n",
      "[0]\teval-mlogloss:2.03632\ttrain-mlogloss:2.03509\n",
      "[500]\teval-mlogloss:0.624465\ttrain-mlogloss:0.424083\n",
      "[1000]\teval-mlogloss:0.540578\ttrain-mlogloss:0.311468\n",
      "[1500]\teval-mlogloss:0.515695\ttrain-mlogloss:0.279912\n"
     ]
    }
   ],
   "source": [
    "clfs = train_xgboost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dir = 'data/test/test_stg1/'\n",
    "test_images = [test_dir+f for f in os.listdir(test_dir) if re.search('jpg|JPG', f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_tst_feat(list_images):\n",
    "    nb_features = 2048\n",
    "    features = np.empty((len(list_images), nb_features))\n",
    "    create_graph()\n",
    "    with tf.Session() as sess:\n",
    "        next_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "        \n",
    "        for ind, image in enumerate(list_images):\n",
    "            if not gfile.Exists(image):\n",
    "                tf.logging.fatal('File does not exist %s', image)\n",
    "            image_data = gfile.FastGFile(image, 'rb').read()\n",
    "            predictions = sess.run(next_to_last_tensor,\n",
    "            {'DecodeJpeg/contents:0': image_data})\n",
    "            features[ind,:] = np.squeeze(predictions)\n",
    "            \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submit():\n",
    "    features_test = xgb.DMatrix(extract_tst_feat(test_images))\n",
    "    \n",
    "    preds = []\n",
    "    for clf in clfs:\n",
    "        preds.append(np.clip(clf.predict(features_test, ntree_limit=clf.best_ntree_limit), 0.001, 1))\n",
    "        \n",
    "    y_pred = gmean(np.array(preds), axis=0)\n",
    "    \n",
    "    image_id = [i.split('/')[3] for i in test_images]\n",
    "\n",
    "    submit = open('submissions/xgb/-LB_A.csv','w')\n",
    "    submit.write('image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT\\n')\n",
    "\n",
    "    for idx, id_n in enumerate(image_id):\n",
    "        probs = ['%s' % p for p in list(y_pred[idx, :])]\n",
    "        submit.write('%s,%s\\n' % (str(image_id[idx]),','.join(probs)))\n",
    "\n",
    "    submit.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nature Conservance Fish Identification Using CNN Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from glob import iglob\n",
    "from models import Vgg16BN, Inception, Resnet50\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "DATA_HOME_DIR = ROOT_DIR + '/data'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "data_path = DATA_HOME_DIR + '/' \n",
    "split_train_path = data_path + '/train/'\n",
    "full_train_path = data_path + '/train_full/'\n",
    "valid_path = data_path + '/valid/'\n",
    "test_path = DATA_HOME_DIR + '/test/'\n",
    "saved_model_path = ROOT_DIR + '/models/'\n",
    "submission_path = ROOT_DIR + '/submissions/'\n",
    "\n",
    "# data\n",
    "batch_size = 16\n",
    "nb_split_train_samples = 3277\n",
    "nb_full_train_samples = 3785\n",
    "nb_valid_samples = 500\n",
    "nb_test_samples = 1000\n",
    "classes = [\"ALB\", \"BET\", \"DOL\", \"LAG\", \"NoF\", \"OTHER\", \"SHARK\", \"YFT\"]\n",
    "nb_classes = len(classes)\n",
    "\n",
    "# model\n",
    "nb_runs = 5\n",
    "nb_epoch = 30\n",
    "nb_aug = 5\n",
    "dropout = 0.4\n",
    "clip = 0.01\n",
    "use_val = True\n",
    "archs = [\"inception\"]\n",
    "\n",
    "models = {\n",
    "    \"vggbn\": Vgg16BN(size=(270, 480), n_classes=nb_classes, lr=0.001,\n",
    "                           batch_size=batch_size, dropout=dropout),\n",
    "    \"inception\": Inception(size=(299, 299), n_classes=nb_classes,\n",
    "                           lr=0.001, batch_size=batch_size),\n",
    "    \"resnet\": Resnet50(size=(270, 480), n_classes=nb_classes, lr=0.001,\n",
    "                    batch_size=batch_size, dropout=dropout)\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a training loop that runs `nb_runs` times and trains a model for each architecture we've specified. \n",
    "\n",
    "We have the option to use validation data or the full training set -- if we use \n",
    "the former, the best model from each training loop will be saved and the path appended to our `models` list for \n",
    "later use; if the latter, we just save the weights from the last epoch of each training loop, since there's no validation monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(parent_model, model_str):\n",
    "    parent_model.build()    \n",
    "    model_fn = saved_model_path + '{val_loss:.2f}-loss_{epoch}epoch_' + model_str\n",
    "    ckpt = ModelCheckpoint(filepath=model_fn, monitor='val_loss',\n",
    "                           save_best_only=True, save_weights_only=True)\n",
    "    \n",
    "    if use_val:\n",
    "        parent_model.fit_val(split_train_path, valid_path, nb_trn_samples=nb_split_train_samples, \n",
    "                             nb_val_samples=nb_valid_samples, nb_epoch=nb_epoch, callbacks=[ckpt], aug=nb_aug)\n",
    "\n",
    "        model_path = max(iglob(saved_model_path + '*.h5'), key=os.path.getctime)\n",
    "        return model_path\n",
    "    \n",
    "    model_fn = saved_model_path + '{}epoch_'.format(nb_epoch) + model_str\n",
    "    parent_model.fit_full(full_train_path, nb_trn_samples=nb_full_train_samples, nb_epoch=nb_epoch, aug=nb_aug)\n",
    "    model.save_weights(model_fn)\n",
    "    del parent_model.model \n",
    "    \n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Run 1 of 5...\n",
      "\n",
      "Training inception model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/applications/inception_v3.py:300: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image dimension ordering convention (`image_dim_ordering=\"th\"`). For best performance, set `image_dim_ordering=\"tf\"` in your Keras config at ~/.keras/keras.json.\n",
      "  warnings.warn('You are using the TensorFlow backend, yet you '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3277 images belonging to 8 classes.\n",
      "Found 500 images belonging to 8 classes.\n",
      "Epoch 1/30\n",
      "189s - loss: 2.0496 - acc: 0.2197 - val_loss: 2.3509 - val_acc: 0.1460\n",
      "Epoch 2/30\n",
      "182s - loss: 1.7985 - acc: 0.3512 - val_loss: 2.5345 - val_acc: 0.1520\n",
      "Epoch 3/30\n",
      "182s - loss: 1.6787 - acc: 0.4300 - val_loss: 2.2812 - val_acc: 0.2020\n",
      "Epoch 4/30\n",
      "182s - loss: 1.6129 - acc: 0.4461 - val_loss: 2.3448 - val_acc: 0.2180\n",
      "Epoch 5/30\n",
      "182s - loss: 1.5476 - acc: 0.4706 - val_loss: 2.3452 - val_acc: 0.2220\n",
      "Epoch 6/30\n",
      "182s - loss: 1.4968 - acc: 0.4931 - val_loss: 2.3228 - val_acc: 0.2180\n",
      "Epoch 7/30\n",
      "183s - loss: 1.4673 - acc: 0.4995 - val_loss: 2.0873 - val_acc: 0.2980\n",
      "Epoch 8/30\n",
      "182s - loss: 1.4188 - acc: 0.5246 - val_loss: 2.2258 - val_acc: 0.2400\n",
      "Epoch 9/30\n",
      "182s - loss: 1.3826 - acc: 0.5444 - val_loss: 2.0747 - val_acc: 0.3100\n",
      "Epoch 10/30\n",
      "182s - loss: 1.3569 - acc: 0.5426 - val_loss: 2.1110 - val_acc: 0.2900\n",
      "Epoch 11/30\n",
      "182s - loss: 1.3546 - acc: 0.5450 - val_loss: 1.9437 - val_acc: 0.3440\n",
      "Epoch 12/30\n",
      "182s - loss: 1.3192 - acc: 0.5447 - val_loss: 1.9804 - val_acc: 0.3400\n",
      "Epoch 13/30\n",
      "182s - loss: 1.3078 - acc: 0.5615 - val_loss: 1.9295 - val_acc: 0.3540\n",
      "Epoch 14/30\n",
      "182s - loss: 1.2931 - acc: 0.5688 - val_loss: 1.8086 - val_acc: 0.3720\n",
      "Epoch 15/30\n",
      "182s - loss: 1.2602 - acc: 0.5755 - val_loss: 1.7721 - val_acc: 0.3740\n",
      "Epoch 16/30\n",
      "182s - loss: 1.2547 - acc: 0.5807 - val_loss: 1.7898 - val_acc: 0.3800\n",
      "Epoch 17/30\n",
      "182s - loss: 1.2117 - acc: 0.5972 - val_loss: 1.7722 - val_acc: 0.3860\n",
      "Epoch 18/30\n",
      "182s - loss: 1.2136 - acc: 0.5896 - val_loss: 1.6565 - val_acc: 0.4380\n",
      "Epoch 19/30\n",
      "182s - loss: 1.1817 - acc: 0.6112 - val_loss: 1.6676 - val_acc: 0.4560\n",
      "Epoch 20/30\n",
      "182s - loss: 1.1773 - acc: 0.6109 - val_loss: 1.5800 - val_acc: 0.4840\n",
      "Epoch 21/30\n",
      "182s - loss: 1.1753 - acc: 0.5987 - val_loss: 1.6184 - val_acc: 0.4680\n",
      "Epoch 22/30\n",
      "182s - loss: 1.1647 - acc: 0.6073 - val_loss: 1.5149 - val_acc: 0.5080\n",
      "Epoch 23/30\n",
      "182s - loss: 1.1439 - acc: 0.6179 - val_loss: 1.4846 - val_acc: 0.5140\n",
      "Epoch 24/30\n",
      "182s - loss: 1.1171 - acc: 0.6311 - val_loss: 1.5274 - val_acc: 0.5000\n",
      "Epoch 25/30\n",
      "182s - loss: 1.1361 - acc: 0.6192 - val_loss: 1.5131 - val_acc: 0.4920\n",
      "Epoch 26/30\n",
      "182s - loss: 1.1093 - acc: 0.6317 - val_loss: 1.4547 - val_acc: 0.5180\n",
      "Epoch 27/30\n",
      "182s - loss: 1.1097 - acc: 0.6286 - val_loss: 1.4396 - val_acc: 0.5220\n",
      "Epoch 28/30\n",
      "182s - loss: 1.0851 - acc: 0.6393 - val_loss: 1.4025 - val_acc: 0.5460\n",
      "Epoch 29/30\n",
      "182s - loss: 1.0779 - acc: 0.6372 - val_loss: 1.3937 - val_acc: 0.5320\n",
      "Epoch 30/30\n",
      "181s - loss: 1.0737 - acc: 0.6427 - val_loss: 1.4029 - val_acc: 0.5340\n",
      "Starting Training Run 2 of 5...\n",
      "\n",
      "Training inception model...\n",
      "\n",
      "Found 3277 images belonging to 8 classes.\n",
      "Found 500 images belonging to 8 classes.\n",
      "Epoch 1/30\n",
      "193s - loss: 2.0314 - acc: 0.2472 - val_loss: 2.5713 - val_acc: 0.1380\n",
      "Epoch 2/30\n",
      "182s - loss: 1.8138 - acc: 0.3512 - val_loss: 2.4770 - val_acc: 0.1780\n",
      "Epoch 3/30\n",
      "182s - loss: 1.6705 - acc: 0.4202 - val_loss: 2.3222 - val_acc: 0.2520\n",
      "Epoch 4/30\n",
      "182s - loss: 1.6092 - acc: 0.4538 - val_loss: 2.4292 - val_acc: 0.2180\n",
      "Epoch 5/30\n",
      "182s - loss: 1.5389 - acc: 0.4699 - val_loss: 2.3106 - val_acc: 0.2400\n",
      "Epoch 6/30\n",
      "182s - loss: 1.5080 - acc: 0.4867 - val_loss: 2.3262 - val_acc: 0.2740\n",
      "Epoch 7/30\n",
      "182s - loss: 1.4690 - acc: 0.5011 - val_loss: 2.1852 - val_acc: 0.3180\n",
      "Epoch 8/30\n",
      "182s - loss: 1.4108 - acc: 0.5252 - val_loss: 2.2308 - val_acc: 0.2940\n",
      "Epoch 9/30\n",
      "182s - loss: 1.3947 - acc: 0.5246 - val_loss: 2.1739 - val_acc: 0.3160\n",
      "Epoch 10/30\n",
      "182s - loss: 1.3670 - acc: 0.5404 - val_loss: 2.1247 - val_acc: 0.3180\n",
      "Epoch 11/30\n",
      "182s - loss: 1.3435 - acc: 0.5478 - val_loss: 1.9927 - val_acc: 0.3820\n",
      "Epoch 12/30\n",
      "182s - loss: 1.3408 - acc: 0.5545 - val_loss: 2.0171 - val_acc: 0.3760\n",
      "Epoch 13/30\n",
      "182s - loss: 1.3034 - acc: 0.5517 - val_loss: 1.8619 - val_acc: 0.3940\n",
      "Epoch 14/30\n",
      "182s - loss: 1.2797 - acc: 0.5703 - val_loss: 1.9575 - val_acc: 0.3920\n",
      "Epoch 15/30\n",
      "182s - loss: 1.2547 - acc: 0.5822 - val_loss: 1.7851 - val_acc: 0.4720\n",
      "Epoch 16/30\n",
      "182s - loss: 1.2394 - acc: 0.5862 - val_loss: 1.7662 - val_acc: 0.4280\n",
      "Epoch 17/30\n",
      "182s - loss: 1.2225 - acc: 0.5838 - val_loss: 1.8873 - val_acc: 0.4020\n",
      "Epoch 18/30\n",
      "182s - loss: 1.2188 - acc: 0.5890 - val_loss: 1.7168 - val_acc: 0.4680\n",
      "Epoch 19/30\n",
      "182s - loss: 1.1970 - acc: 0.5938 - val_loss: 1.6157 - val_acc: 0.4960\n",
      "Epoch 20/30\n",
      "182s - loss: 1.1941 - acc: 0.5996 - val_loss: 1.6788 - val_acc: 0.4600\n",
      "Epoch 21/30\n",
      "182s - loss: 1.1673 - acc: 0.6070 - val_loss: 1.6274 - val_acc: 0.4660\n",
      "Epoch 22/30\n",
      "182s - loss: 1.1374 - acc: 0.6253 - val_loss: 1.6227 - val_acc: 0.4780\n",
      "Epoch 23/30\n",
      "182s - loss: 1.1395 - acc: 0.6182 - val_loss: 1.5951 - val_acc: 0.4920\n",
      "Epoch 24/30\n",
      "182s - loss: 1.1381 - acc: 0.6222 - val_loss: 1.5805 - val_acc: 0.4960\n",
      "Epoch 25/30\n",
      "182s - loss: 1.1288 - acc: 0.6247 - val_loss: 1.5760 - val_acc: 0.5160\n",
      "Epoch 26/30\n",
      "182s - loss: 1.1168 - acc: 0.6286 - val_loss: 1.4739 - val_acc: 0.5440\n",
      "Epoch 27/30\n",
      "182s - loss: 1.0945 - acc: 0.6308 - val_loss: 1.5018 - val_acc: 0.5320\n",
      "Epoch 28/30\n",
      "182s - loss: 1.1097 - acc: 0.6259 - val_loss: 1.4644 - val_acc: 0.5660\n",
      "Epoch 29/30\n",
      "182s - loss: 1.0734 - acc: 0.6320 - val_loss: 1.4462 - val_acc: 0.5540\n",
      "Epoch 30/30\n",
      "182s - loss: 1.0574 - acc: 0.6485 - val_loss: 1.3365 - val_acc: 0.6020\n",
      "Starting Training Run 3 of 5...\n",
      "\n",
      "Training inception model...\n",
      "\n",
      "Found 3277 images belonging to 8 classes.\n",
      "Found 500 images belonging to 8 classes.\n",
      "Epoch 1/30\n",
      "198s - loss: 2.0098 - acc: 0.2392 - val_loss: 2.3542 - val_acc: 0.1520\n",
      "Epoch 2/30\n",
      "182s - loss: 1.7980 - acc: 0.3634 - val_loss: 2.3203 - val_acc: 0.2000\n",
      "Epoch 3/30\n",
      "182s - loss: 1.6804 - acc: 0.4126 - val_loss: 2.3916 - val_acc: 0.2000\n",
      "Epoch 4/30\n",
      "182s - loss: 1.6064 - acc: 0.4501 - val_loss: 2.3540 - val_acc: 0.2300\n",
      "Epoch 5/30\n",
      "182s - loss: 1.5522 - acc: 0.4760 - val_loss: 2.3208 - val_acc: 0.2620\n",
      "Epoch 6/30\n",
      "182s - loss: 1.4965 - acc: 0.4916 - val_loss: 2.1650 - val_acc: 0.2860\n",
      "Epoch 7/30\n",
      "182s - loss: 1.4836 - acc: 0.4995 - val_loss: 2.2250 - val_acc: 0.2880\n",
      "Epoch 8/30\n",
      "182s - loss: 1.4367 - acc: 0.5130 - val_loss: 2.2715 - val_acc: 0.3020\n",
      "Epoch 9/30\n",
      "182s - loss: 1.4044 - acc: 0.5301 - val_loss: 1.9838 - val_acc: 0.3260\n",
      "Epoch 10/30\n",
      "182s - loss: 1.3592 - acc: 0.5417 - val_loss: 2.0026 - val_acc: 0.3200\n",
      "Epoch 11/30\n",
      "182s - loss: 1.3484 - acc: 0.5502 - val_loss: 2.0418 - val_acc: 0.3180\n",
      "Epoch 12/30\n",
      "182s - loss: 1.3135 - acc: 0.5587 - val_loss: 2.0791 - val_acc: 0.3160\n",
      "Epoch 13/30\n",
      "182s - loss: 1.2934 - acc: 0.5627 - val_loss: 1.9764 - val_acc: 0.3500\n",
      "Epoch 14/30\n",
      "182s - loss: 1.2915 - acc: 0.5633 - val_loss: 1.8473 - val_acc: 0.3740\n",
      "Epoch 15/30\n",
      "182s - loss: 1.2583 - acc: 0.5703 - val_loss: 1.8324 - val_acc: 0.3840\n",
      "Epoch 16/30\n",
      "182s - loss: 1.2453 - acc: 0.5816 - val_loss: 1.8846 - val_acc: 0.3760\n",
      "Epoch 17/30\n",
      "182s - loss: 1.2230 - acc: 0.5896 - val_loss: 1.8564 - val_acc: 0.3840\n",
      "Epoch 18/30\n",
      "182s - loss: 1.2277 - acc: 0.6027 - val_loss: 1.7652 - val_acc: 0.4200\n",
      "Epoch 19/30\n",
      "182s - loss: 1.1910 - acc: 0.5932 - val_loss: 1.9361 - val_acc: 0.3660\n",
      "Epoch 20/30\n",
      "182s - loss: 1.1834 - acc: 0.5975 - val_loss: 1.7187 - val_acc: 0.4180\n",
      "Epoch 21/30\n",
      "182s - loss: 1.1743 - acc: 0.6060 - val_loss: 1.7350 - val_acc: 0.4220\n",
      "Epoch 22/30\n",
      "182s - loss: 1.1605 - acc: 0.6060 - val_loss: 1.4832 - val_acc: 0.5120\n",
      "Epoch 23/30\n",
      "182s - loss: 1.1413 - acc: 0.6167 - val_loss: 1.6061 - val_acc: 0.4680\n",
      "Epoch 24/30\n",
      "182s - loss: 1.1410 - acc: 0.6161 - val_loss: 1.6193 - val_acc: 0.4360\n",
      "Epoch 25/30\n",
      "182s - loss: 1.1357 - acc: 0.6149 - val_loss: 1.5649 - val_acc: 0.4880\n",
      "Epoch 26/30\n",
      "182s - loss: 1.1145 - acc: 0.6268 - val_loss: 1.5175 - val_acc: 0.4960\n",
      "Epoch 27/30\n",
      "182s - loss: 1.1097 - acc: 0.6347 - val_loss: 1.4648 - val_acc: 0.5080\n",
      "Epoch 28/30\n",
      "182s - loss: 1.1070 - acc: 0.6295 - val_loss: 1.4353 - val_acc: 0.5360\n",
      "Epoch 29/30\n",
      "182s - loss: 1.0882 - acc: 0.6442 - val_loss: 1.4047 - val_acc: 0.5200\n",
      "Epoch 30/30\n",
      "182s - loss: 1.0576 - acc: 0.6527 - val_loss: 1.4419 - val_acc: 0.5200\n",
      "Starting Training Run 4 of 5...\n",
      "\n",
      "Training inception model...\n",
      "\n",
      "Found 3277 images belonging to 8 classes.\n",
      "Found 500 images belonging to 8 classes.\n",
      "Epoch 1/30\n",
      "203s - loss: 2.0175 - acc: 0.2368 - val_loss: 2.2902 - val_acc: 0.1500\n",
      "Epoch 2/30\n",
      "182s - loss: 1.8003 - acc: 0.3653 - val_loss: 2.2620 - val_acc: 0.1960\n",
      "Epoch 3/30\n",
      "182s - loss: 1.7005 - acc: 0.4141 - val_loss: 2.2496 - val_acc: 0.2240\n",
      "Epoch 4/30\n",
      "182s - loss: 1.6167 - acc: 0.4513 - val_loss: 2.3313 - val_acc: 0.2080\n",
      "Epoch 5/30\n",
      "182s - loss: 1.5699 - acc: 0.4663 - val_loss: 2.1929 - val_acc: 0.2420\n",
      "Epoch 6/30\n",
      "182s - loss: 1.5312 - acc: 0.4764 - val_loss: 1.9673 - val_acc: 0.3040\n",
      "Epoch 7/30\n",
      "182s - loss: 1.4797 - acc: 0.5011 - val_loss: 1.9565 - val_acc: 0.2920\n",
      "Epoch 8/30\n",
      "182s - loss: 1.4670 - acc: 0.5008 - val_loss: 2.0699 - val_acc: 0.2940\n",
      "Epoch 9/30\n",
      "182s - loss: 1.4170 - acc: 0.5169 - val_loss: 1.8114 - val_acc: 0.3660\n",
      "Epoch 10/30\n",
      "182s - loss: 1.3996 - acc: 0.5294 - val_loss: 1.8781 - val_acc: 0.3140\n",
      "Epoch 11/30\n",
      "182s - loss: 1.3682 - acc: 0.5316 - val_loss: 1.8235 - val_acc: 0.3760\n",
      "Epoch 12/30\n",
      "182s - loss: 1.3533 - acc: 0.5352 - val_loss: 1.9736 - val_acc: 0.3000\n",
      "Epoch 13/30\n",
      "182s - loss: 1.3401 - acc: 0.5487 - val_loss: 1.8108 - val_acc: 0.3660\n",
      "Epoch 14/30\n",
      "182s - loss: 1.3026 - acc: 0.5551 - val_loss: 1.8078 - val_acc: 0.3700\n",
      "Epoch 15/30\n",
      "182s - loss: 1.2885 - acc: 0.5645 - val_loss: 1.8208 - val_acc: 0.3840\n",
      "Epoch 16/30\n",
      "182s - loss: 1.2710 - acc: 0.5774 - val_loss: 1.7134 - val_acc: 0.4260\n",
      "Epoch 17/30\n",
      "182s - loss: 1.2368 - acc: 0.5853 - val_loss: 1.7413 - val_acc: 0.4280\n",
      "Epoch 18/30\n",
      "182s - loss: 1.2262 - acc: 0.5880 - val_loss: 1.6546 - val_acc: 0.4620\n",
      "Epoch 19/30\n",
      "182s - loss: 1.2260 - acc: 0.5957 - val_loss: 1.6603 - val_acc: 0.4420\n",
      "Epoch 20/30\n",
      "182s - loss: 1.1967 - acc: 0.5981 - val_loss: 1.6335 - val_acc: 0.4740\n",
      "Epoch 21/30\n",
      "182s - loss: 1.1873 - acc: 0.6063 - val_loss: 1.5559 - val_acc: 0.5000\n",
      "Epoch 22/30\n",
      "182s - loss: 1.1720 - acc: 0.6036 - val_loss: 1.6295 - val_acc: 0.4740\n",
      "Epoch 23/30\n",
      "182s - loss: 1.1644 - acc: 0.6079 - val_loss: 1.4725 - val_acc: 0.5060\n",
      "Epoch 24/30\n",
      "182s - loss: 1.1413 - acc: 0.6143 - val_loss: 1.4919 - val_acc: 0.5080\n",
      "Epoch 25/30\n",
      "182s - loss: 1.1293 - acc: 0.6125 - val_loss: 1.3481 - val_acc: 0.5700\n",
      "Epoch 26/30\n",
      "182s - loss: 1.1290 - acc: 0.6289 - val_loss: 1.4448 - val_acc: 0.5100\n",
      "Epoch 27/30\n",
      "182s - loss: 1.1011 - acc: 0.6332 - val_loss: 1.3328 - val_acc: 0.5660\n",
      "Epoch 28/30\n",
      "182s - loss: 1.0971 - acc: 0.6298 - val_loss: 1.3728 - val_acc: 0.5560\n",
      "Epoch 29/30\n",
      "182s - loss: 1.0780 - acc: 0.6359 - val_loss: 1.3045 - val_acc: 0.5980\n",
      "Epoch 30/30\n",
      "182s - loss: 1.0892 - acc: 0.6369 - val_loss: 1.3471 - val_acc: 0.5660\n",
      "Starting Training Run 5 of 5...\n",
      "\n",
      "Training inception model...\n",
      "\n",
      "Found 3277 images belonging to 8 classes.\n",
      "Found 500 images belonging to 8 classes.\n",
      "Epoch 1/30\n",
      "208s - loss: 2.0656 - acc: 0.1950 - val_loss: 2.3710 - val_acc: 0.1240\n",
      "Epoch 2/30\n",
      "182s - loss: 1.8366 - acc: 0.3454 - val_loss: 2.4907 - val_acc: 0.1520\n",
      "Epoch 3/30\n",
      "182s - loss: 1.7144 - acc: 0.4031 - val_loss: 2.3483 - val_acc: 0.2300\n",
      "Epoch 4/30\n",
      "182s - loss: 1.6580 - acc: 0.4352 - val_loss: 2.3487 - val_acc: 0.2340\n",
      "Epoch 5/30\n",
      "182s - loss: 1.5770 - acc: 0.4590 - val_loss: 2.3577 - val_acc: 0.2460\n",
      "Epoch 6/30\n",
      "182s - loss: 1.5319 - acc: 0.4846 - val_loss: 2.2786 - val_acc: 0.2900\n",
      "Epoch 7/30\n",
      "182s - loss: 1.5010 - acc: 0.4940 - val_loss: 2.2432 - val_acc: 0.2900\n",
      "Epoch 8/30\n",
      "182s - loss: 1.4588 - acc: 0.5124 - val_loss: 2.1796 - val_acc: 0.3080\n",
      "Epoch 9/30\n",
      "182s - loss: 1.4110 - acc: 0.5304 - val_loss: 2.0977 - val_acc: 0.3180\n",
      "Epoch 10/30\n",
      "182s - loss: 1.3935 - acc: 0.5240 - val_loss: 2.1033 - val_acc: 0.3300\n",
      "Epoch 11/30\n",
      "182s - loss: 1.3694 - acc: 0.5319 - val_loss: 2.0444 - val_acc: 0.3480\n",
      "Epoch 12/30\n",
      "182s - loss: 1.3481 - acc: 0.5413 - val_loss: 1.7953 - val_acc: 0.3960\n",
      "Epoch 13/30\n",
      "182s - loss: 1.3178 - acc: 0.5471 - val_loss: 1.7511 - val_acc: 0.4300\n",
      "Epoch 14/30\n",
      "182s - loss: 1.3081 - acc: 0.5551 - val_loss: 1.8179 - val_acc: 0.4140\n",
      "Epoch 15/30\n",
      "182s - loss: 1.2712 - acc: 0.5667 - val_loss: 1.8331 - val_acc: 0.3920\n",
      "Epoch 16/30\n",
      "183s - loss: 1.2461 - acc: 0.5786 - val_loss: 1.8171 - val_acc: 0.4220\n",
      "Epoch 17/30\n",
      "182s - loss: 1.2420 - acc: 0.5743 - val_loss: 1.8626 - val_acc: 0.4020\n",
      "Epoch 18/30\n",
      "182s - loss: 1.2265 - acc: 0.5923 - val_loss: 1.8116 - val_acc: 0.4300\n",
      "Epoch 19/30\n",
      "183s - loss: 1.2096 - acc: 0.5972 - val_loss: 1.7276 - val_acc: 0.4360\n",
      "Epoch 20/30\n",
      "183s - loss: 1.1888 - acc: 0.6002 - val_loss: 1.6902 - val_acc: 0.4560\n",
      "Epoch 21/30\n",
      "182s - loss: 1.1683 - acc: 0.6173 - val_loss: 1.7454 - val_acc: 0.4040\n",
      "Epoch 22/30\n",
      "182s - loss: 1.1680 - acc: 0.6143 - val_loss: 1.7015 - val_acc: 0.4540\n",
      "Epoch 23/30\n",
      "182s - loss: 1.1581 - acc: 0.6048 - val_loss: 1.5746 - val_acc: 0.5000\n",
      "Epoch 24/30\n",
      "182s - loss: 1.1430 - acc: 0.6179 - val_loss: 1.5349 - val_acc: 0.5140\n",
      "Epoch 25/30\n",
      "182s - loss: 1.1297 - acc: 0.6234 - val_loss: 1.6277 - val_acc: 0.5140\n",
      "Epoch 26/30\n",
      "182s - loss: 1.1356 - acc: 0.6189 - val_loss: 1.4267 - val_acc: 0.5440\n",
      "Epoch 27/30\n",
      "182s - loss: 1.1280 - acc: 0.6204 - val_loss: 1.4144 - val_acc: 0.5440\n",
      "Epoch 28/30\n",
      "182s - loss: 1.1093 - acc: 0.6265 - val_loss: 1.4359 - val_acc: 0.5520\n",
      "Epoch 29/30\n",
      "182s - loss: 1.0978 - acc: 0.6332 - val_loss: 1.5035 - val_acc: 0.5460\n",
      "Epoch 30/30\n",
      "182s - loss: 1.0886 - acc: 0.6359 - val_loss: 1.4446 - val_acc: 0.5620\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def train_all():    \n",
    "    model_paths = {\n",
    "        \"vggbn\": [],\n",
    "        \"inception\": [],\n",
    "        'resnet': [],\n",
    "    }\n",
    "    \n",
    "    for run in range(nb_runs):\n",
    "        print(\"Starting Training Run {0} of {1}...\\n\".format(run+1, nb_runs))\n",
    "        aug_str = \"aug\" if nb_aug else \"no-aug\"\n",
    "        \n",
    "        for arch in archs:\n",
    "            print(\"Training {} model...\\n\".format(arch))\n",
    "            model = models[arch]\n",
    "            model_str = \"{0}x{1}_{2}_{3}lr_run{4}_{5}.h5\".format(model.size[0], model.size[1], aug_str,\n",
    "                                                                 model.lr, run, arch)\n",
    "            model_path = train(model, model_str)\n",
    "            model_paths[arch].append(model_path)\n",
    "        \n",
    "    print(\"Done.\") \n",
    "    return model_paths\n",
    "        \n",
    "model_paths = train_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Prediction Run 1 of 5...\n",
      "\n",
      "\n",
      "--Predicting on Augmentation 1 of 5...\n",
      "\n",
      "----Predicting on inception model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/applications/inception_v3.py:300: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image dimension ordering convention (`image_dim_ordering=\"th\"`). For best performance, set `image_dim_ordering=\"tf\"` in your Keras config at ~/.keras/keras.json.\n",
      "  warnings.warn('You are using the TensorFlow backend, yet you '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 2 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 3 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 4 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 5 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "Starting Prediction Run 2 of 5...\n",
      "\n",
      "\n",
      "--Predicting on Augmentation 1 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 2 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 3 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 4 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 5 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "Starting Prediction Run 3 of 5...\n",
      "\n",
      "\n",
      "--Predicting on Augmentation 1 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 2 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 3 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 4 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 5 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "Starting Prediction Run 4 of 5...\n",
      "\n",
      "\n",
      "--Predicting on Augmentation 1 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 2 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 3 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 4 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 5 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "Starting Prediction Run 5 of 5...\n",
      "\n",
      "\n",
      "--Predicting on Augmentation 1 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 2 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 3 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 4 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 5 of 5...\n",
      "\n",
      "----Predicting on inception model...\n",
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "def test(model_paths):    \n",
    "    predictions_full = np.zeros((nb_test_samples, nb_classes))\n",
    "    \n",
    "    for run in range(nb_runs):\n",
    "        print(\"\\nStarting Prediction Run {0} of {1}...\\n\".format(run+1, nb_runs))\n",
    "        predictions_aug = np.zeros((nb_test_samples, nb_classes))\n",
    "        \n",
    "        for aug in range(nb_aug):\n",
    "            print(\"\\n--Predicting on Augmentation {0} of {1}...\\n\".format(aug+1, nb_aug))\n",
    "            predictions_mod = np.zeros((nb_test_samples, nb_classes))\n",
    "            \n",
    "            for arch in archs:\n",
    "                print(\"----Predicting on {} model...\".format(arch))\n",
    "                parent = models[arch]\n",
    "                model = parent.build()\n",
    "                model.load_weights(model_paths[arch][run])\n",
    "                pred, filenames = parent.test(test_path, nb_test_samples, aug=nb_aug)\n",
    "                predictions_mod += pred\n",
    "            \n",
    "            predictions_mod /= len(archs)\n",
    "            predictions_aug += predictions_mod\n",
    "\n",
    "        predictions_aug /= nb_aug\n",
    "        predictions_full += predictions_aug\n",
    "    \n",
    "    predictions_full /= nb_runs\n",
    "    return predictions_full, filenames\n",
    "\n",
    "predictions, filenames = test(model_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Predictions to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Predictions to CSV...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def write_submission(predictions, filenames):\n",
    "    preds = np.clip(predictions, clip, 1-clip)\n",
    "    sub_fn = submission_path + '{0}epoch_{1}aug_{2}clip_{3}runs'.format(nb_epoch, nb_aug, clip, nb_runs)\n",
    "    \n",
    "    for arch in archs:\n",
    "        sub_fn += \"_{}\".format(arch)\n",
    "\n",
    "    with open(sub_fn + '.csv', 'w') as f:\n",
    "        print(\"Writing Predictions to CSV...\")\n",
    "        f.write('image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT\\n')\n",
    "        for i, image_name in enumerate(filenames):\n",
    "            pred = ['%.6f' % p for p in preds[i, :]]\n",
    "            f.write('%s,%s\\n' % (os.path.basename(image_name), ','.join(pred)))\n",
    "        print(\"Done.\")\n",
    "\n",
    "write_submission(predictions, filenames)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nature Conservancy Fish Classification - Bounding Box End-to-End Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import GlobalAveragePooling2D, Activation, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from vgg16bn import Vgg16BN as VggConv\n",
    "\n",
    "from utils import * \n",
    "from models import Vgg16BN, Inception, Resnet50\n",
    "from glob import iglob\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "DATA_HOME_DIR = ROOT_DIR + '/data'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ipl/Downloads/0126/train/nc-fish-classification/nc_fish_classification'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ROOT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "data_path = DATA_HOME_DIR + '/cropped' \n",
    "split_train_path = data_path + '/train/'\n",
    "valid_path = data_path + '/valid/'\n",
    "test_path = DATA_HOME_DIR + '/test/'\n",
    "saved_model_path = ROOT_DIR + '/models/bb_end_to_end/'\n",
    "submission_path = ROOT_DIR + '/submissions/bb_end_to_end/'\n",
    "fish_detector_path = ROOT_DIR + '/models/fish_detector_480x270/0.03-loss_2epoch_480x270_0.3-dropout_0.001-lr_vggbn.h5'\n",
    "bb_regressor_path = 'models/bb_regressor/360x640/loss-1248.00_vgg16_bn.h5'\n",
    "\n",
    "# data\n",
    "batch_size = 16\n",
    "im_size = (224, 224)  # (ht, wt); only 299x299 for inception\n",
    "nb_split_train_samples = 2847\n",
    "nb_valid_samples = 450\n",
    "nb_test_samples = 1000\n",
    "classes = [\"ALB\", \"BET\", \"DOL\", \"LAG\", \"OTHER\", \"SHARK\", \"YFT\"]\n",
    "nb_classes = len(classes)\n",
    "\n",
    "# model\n",
    "nb_runs = 1\n",
    "nb_epoch = 12\n",
    "nb_aug = 1\n",
    "dropout = 0.5\n",
    "lr=0.001           \n",
    "clip = 0.01\n",
    "archs = [\"vggbn\"]\n",
    "\n",
    "models = {\n",
    "    \"vggbn\": Vgg16BN(size=im_size, n_classes=nb_classes, lr=lr,\n",
    "                           batch_size=batch_size, dropout=dropout),\n",
    "    \"inception\": Inception(size=(299, 299), n_classes=nb_classes,\n",
    "                           lr=0.001, batch_size=batch_size),\n",
    "    \"resnet\": Resnet50(size=im_size, n_classes=nb_classes, lr=lr,\n",
    "                    batch_size=batch_size, dropout=dropout)\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build & Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(parent_model, model_str):\n",
    "    parent_model.build()    \n",
    "    model_fn = saved_model_path + '{val_loss:.2f}-loss_{epoch}epoch_' + model_str\n",
    "    ckpt = ModelCheckpoint(filepath=model_fn, monitor='val_loss',\n",
    "                           save_best_only=True, save_weights_only=True)\n",
    "    \n",
    "    parent_model.fit_val(split_train_path, valid_path, nb_trn_samples=nb_split_train_samples, \n",
    "                         nb_val_samples=nb_valid_samples, nb_epoch=nb_epoch, callbacks=[ckpt], aug=nb_aug)\n",
    "\n",
    "    model_path = max(iglob(saved_model_path + '*.h5'), key=os.path.getctime)\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Run 1 of 1...\n",
      "\n",
      "Training vggbn model...\n",
      "\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[25088,4096]\n\t [[Node: random_uniform_13/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=734155570, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](random_uniform_13/shape)]]\n\nCaused by op 'random_uniform_13/RandomUniform', defined at:\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-b7cb464f9e79>\", line 23, in <module>\n    model_paths = train_all()\n  File \"<ipython-input-5-b7cb464f9e79>\", line 17, in train_all\n    model_path = train(model, model_str)\n  File \"<ipython-input-4-235fd2c24872>\", line 2, in train\n    parent_model.build()\n  File \"/home/ipl/Downloads/0126/train/nc-fish-classification/nc_fish_classification/models.py\", line 83, in build\n    model.add(Dense(4096, activation='relu'))\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/models.py\", line 332, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/engine/topology.py\", line 546, in __call__\n    self.build(input_shapes[0])\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/layers/core.py\", line 798, in build\n    constraint=self.W_constraint)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/engine/topology.py\", line 418, in add_weight\n    weight = initializer(shape, name=name)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/initializations.py\", line 66, in glorot_uniform\n    return uniform(shape, s, name=name)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/initializations.py\", line 33, in uniform\n    return K.random_uniform_variable(shape, -scale, scale, name=name)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 634, in random_uniform_variable\n    low, high, dtype=tf_dtype, seed=seed)(shape)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py\", line 171, in _initializer\n    return random_ops.random_uniform(shape, minval, maxval, dtype, seed=seed)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\", line 245, in random_uniform\n    seed2=seed2)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 220, in _random_uniform\n    seed=seed, seed2=seed2, name=name)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[25088,4096]\n\t [[Node: random_uniform_13/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=734155570, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](random_uniform_13/shape)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ipl/anaconda2/envs/py3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[25088,4096]\n\t [[Node: random_uniform_13/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=734155570, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](random_uniform_13/shape)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b7cb464f9e79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-b7cb464f9e79>\u001b[0m in \u001b[0;36mtrain_all\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m             model_str = \"{0}x{1}_{2}_{3}lr_run{4}_{5}.h5\".format(model.size[0], model.size[1], aug_str,\n\u001b[1;32m     16\u001b[0m                                                                  model.lr, run, arch)\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mmodel_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-235fd2c24872>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(parent_model, model_str)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mparent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'{val_loss:.2f}-loss_{epoch}epoch_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     ckpt = ModelCheckpoint(filepath=model_fn, monitor='val_loss',\n\u001b[1;32m      5\u001b[0m                            save_best_only=True, save_weights_only=True)\n",
      "\u001b[0;32m/home/ipl/Downloads/0126/train/nc-fish-classification/nc_fish_classification/models.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   2706\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2708\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   2792\u001b[0m                         \u001b[0mweight_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2793\u001b[0m                 \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2794\u001b[0;31m             \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2796\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   1879\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m()\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'variables_initializer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[25088,4096]\n\t [[Node: random_uniform_13/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=734155570, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](random_uniform_13/shape)]]\n\nCaused by op 'random_uniform_13/RandomUniform', defined at:\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-b7cb464f9e79>\", line 23, in <module>\n    model_paths = train_all()\n  File \"<ipython-input-5-b7cb464f9e79>\", line 17, in train_all\n    model_path = train(model, model_str)\n  File \"<ipython-input-4-235fd2c24872>\", line 2, in train\n    parent_model.build()\n  File \"/home/ipl/Downloads/0126/train/nc-fish-classification/nc_fish_classification/models.py\", line 83, in build\n    model.add(Dense(4096, activation='relu'))\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/models.py\", line 332, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/engine/topology.py\", line 546, in __call__\n    self.build(input_shapes[0])\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/layers/core.py\", line 798, in build\n    constraint=self.W_constraint)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/engine/topology.py\", line 418, in add_weight\n    weight = initializer(shape, name=name)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/initializations.py\", line 66, in glorot_uniform\n    return uniform(shape, s, name=name)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/initializations.py\", line 33, in uniform\n    return K.random_uniform_variable(shape, -scale, scale, name=name)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 634, in random_uniform_variable\n    low, high, dtype=tf_dtype, seed=seed)(shape)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py\", line 171, in _initializer\n    return random_ops.random_uniform(shape, minval, maxval, dtype, seed=seed)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\", line 245, in random_uniform\n    seed2=seed2)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 220, in _random_uniform\n    seed=seed, seed2=seed2, name=name)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ipl/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[25088,4096]\n\t [[Node: random_uniform_13/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=734155570, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](random_uniform_13/shape)]]\n"
     ]
    }
   ],
   "source": [
    "def train_all():    \n",
    "    model_paths = {\n",
    "        \"vggbn\": [],\n",
    "        \"inception\": [],\n",
    "        'resnet': [],\n",
    "    }\n",
    "    \n",
    "    for run in range(nb_runs):\n",
    "        print(\"Starting Training Run {0} of {1}...\\n\".format(run+1, nb_runs))\n",
    "        aug_str = \"aug\" if nb_aug else \"no-aug\"\n",
    "        \n",
    "        for arch in archs:\n",
    "            print(\"Training {} model...\\n\".format(arch))\n",
    "            model = models[arch]\n",
    "            model_str = \"{0}x{1}_{2}_{3}lr_run{4}_{5}.h5\".format(model.size[0], model.size[1], aug_str,\n",
    "                                                                 model.lr, run, arch)\n",
    "            model_path = train(model, model_str)\n",
    "            model_paths[arch].append(model_path)\n",
    "        \n",
    "    print(\"Done.\") \n",
    "    return model_paths\n",
    "        \n",
    "model_paths = train_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bb_pred(test_image):  \n",
    "    \n",
    "    # load conv model\n",
    "    vgg_conv = VggConv((360, 640)).model\n",
    "    vgg_conv.pop()\n",
    "    vgg_conv.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # build bb regressor & load weights\n",
    "    input_shape = (512, 22, 40)  # shape of output of conv model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(MaxPooling2D(input_shape=input_shape))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4))\n",
    "\n",
    "    model.compile(Adam(lr=0.001), loss='mse')\n",
    "    model.load_weights(bb_regressor_path)\n",
    "    \n",
    "    # extract conv features from conv model\n",
    "    conv_test_feat = vgg_conv.predict(test_image)\n",
    "    \n",
    "    # predict bounding box coordinates\n",
    "    bb_preds = model.predict(conv_test_feat)\n",
    "    \n",
    "    return bb_preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_preds(model):\n",
    "    fish_detector = Vgg16BN(size=(270, 480), n_classes=2, lr=0.001,\n",
    "                            batch_size=batch_size, dropout=dropout)\n",
    "    fish_detector.build()\n",
    "    fish_detector.model.load_weights(fish_detector_path)\n",
    "\n",
    "    nofish_prob, filenames = fish_detector.test(test_path, nb_test_samples, aug=nb_aug)\n",
    "    nofish_prob = nofish_prob[:, 1]\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for ix, fn in enumerate(filenames):\n",
    "        \n",
    "        if ix % 100 == 0:\n",
    "            print(\"Processing {0} of {1}\".format(ix, len(filenames)))\n",
    "        \n",
    "        im_id = fn.split(\"/\")[-1]\n",
    "        im = Image.open(test_path + fn).resize((640, 360))\n",
    "        test_x = np.array(im)\n",
    "    \n",
    "        # Nofish\n",
    "        if nofish_prob[ix] > 0.5:\n",
    "            alloc = (1. - nofish_prob[ix] / 7.)\n",
    "            pred = np.array([alloc, alloc, alloc, alloc, nofish_prob[ix], alloc, alloc, alloc])\n",
    "            predictions.append(pred)\n",
    "            \n",
    "        # Fish\n",
    "        else:\n",
    "            coords = get_bb_pred(test_x.reshape(1, 3, 360, 640))        \n",
    "            ht = coords[0]\n",
    "            wt = coords[1]\n",
    "            x = coords[2]\n",
    "            y = coords[3]\n",
    "            mx_dim = max([wt, ht])\n",
    "\n",
    "            cropped = im.crop((x, y, x + mx_dim, y + mx_dim)).resize((im_size[1], im_size[0]))\n",
    "            test_x = np.array(cropped).reshape(1, 3, im_size[0], im_size[1])\n",
    "            weight = -1. * (nofish_prob[ix] - 1.)\n",
    "            \n",
    "            pred = model.predict(test_x)\n",
    "            pred = weight * pred\n",
    "            pred = np.insert(pred, 4, nofish_prob[ix], axis=1)\n",
    "            predictions.append(pred)\n",
    "    \n",
    "    return np.array(predictions), filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test(model_paths):   \n",
    "                 \n",
    "    print(\"----Predicting on {} model...\".format(arch))\n",
    "    parent = models[\"vggbn\"]\n",
    "    model = parent.build()\n",
    "    model.load_weights(model_paths[arch][run])\n",
    "    pred, filenames = generate_preds(model)\n",
    "    \n",
    "    predictions = []\n",
    "\n",
    "    # weird, hacky reshaping\n",
    "    for p in pred:\n",
    "        if p.shape != (1, 8):\n",
    "            p = p.reshape(1, 8)\n",
    "        predictions.append(p)\n",
    "        \n",
    "    predictions = np.concatenate([p for p in predictions])\n",
    "    return predictions, filenames\n",
    "\n",
    "predictions, filenames = test(model_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Predictions to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_submission(predictions, filenames):\n",
    "    preds = np.clip(predictions, clip, 1-clip)\n",
    "    sub_fn = submission_path + '{0}epoch_{1}aug_{2}clip_{3}runs'.format(nb_epoch, nb_aug, clip, nb_runs)\n",
    "    \n",
    "    for arch in archs:\n",
    "        sub_fn += \"_{}\".format(arch)\n",
    "\n",
    "    with open(sub_fn + '.csv', 'w') as f:\n",
    "        print(\"Writing Predictions to CSV...\")\n",
    "        f.write('image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT\\n')\n",
    "        for i, image_name in enumerate(filenames):\n",
    "            pred = ['%.6f' % p for p in preds[i, :]]\n",
    "            f.write('%s,%s\\n' % (os.path.basename(image_name), ','.join(pred)))\n",
    "        print(\"Done.\")\n",
    "\n",
    "write_submission(predicitions, filenames)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
